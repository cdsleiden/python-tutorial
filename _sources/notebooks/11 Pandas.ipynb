{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Data analysis with pandas\n",
    "\n",
    "'Pandas' is a Python library which was developed for the manipulation and the analysis of data sets. It is available for Python version 2.7 and higher. The name of the library loosely stands for \"Python Data Analysis Library\". Pandas contains methods that enable programmers to read data from and write data to a wide range of file formats, including CSV, TSV, Excel spreadsheets and MySQL databases, and it offers numerous statistical methods that can be used to analyse these data.\n",
    "\n",
    "If pandas has been installed successfully on your computer, this library can be imported into your program using the `import` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, this import statement also assigns an alias, namely `pd`. This is an abbreviated reference to the `pandas` library. Without this alias, the full name of the library would have to be typed in each time a method from this library is needed.\n",
    "\n",
    "\n",
    "## Reading a CSV file\n",
    "\n",
    "If your data set is stored in the CSV format, it can be accessed using the `read_csv()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv( 'data.csv' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that are read from the csv file are represented as a specific data structure which is known within the context of pandas as a *data frame*. A data frame can be compared to a regular table in a database. It is a data structure consisting of rows and columns. In the code above, the data frame is stored in a variable named '*data_set*'.\n",
    "\n",
    "As is indicated by the name of the file format, CSV files conventionally separate the individual values in the data set using commas. In some cases however, such files may also work with other types of separators, such as hyphens or semi-colons. In the `read_csv()` method, it is possible to indicate explicitly which character should function as a separator. When you use the parameter named `sep`, and assign it the value ‘;’, the semi-colon, this character will be used to separate the rows into individual values.\n",
    "\n",
    "For more information, see the [guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-read-csv-table) on `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv( 'data.csv' , sep = ';' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data set includes floating point numbers, it can also be useful to specify the character that is used as a decimal point via the `decimal` parameter. Floating point numbers are typically represented using either the period or the comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv( 'data.csv' , decimal = '.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading an Excel spreadsheet\n",
    "\n",
    "The Pandas library also offers a method named `read_excel()`. You can use this function, unsurprisingly, to process data stored in an Excel spreadsheet. The method needs to be used with two parameters. The first parameter is simply the name of the Excel file that you want to work with. Secondly, as a value to a parameter named `sheet_name`, you need to provide the name of the sheet within the spreadsheet that you want to read. Similarly to the way in which `read_csv()` processes data, `read_excel()` loads the data on the sheet that you mention into a data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel( 'Data.xlsx' , sheet_name = \"Sheet1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a list into a data frame\n",
    "\n",
    "It is also possible to convert an existing Python list into a data frame, using the `DataFrame()` method. In the code below, the list named `data` is a two-dimensional array. Each item is in fact a list in itself. \n",
    "\n",
    "When you pass this list into `Dataframe()`, the method converts this data structure into a colelction of rows and columns. The `columns` parameter may be used to supply column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ [12,5,6,12,'Class1'], \n",
    "[14,11,17,20,'Class1'], \n",
    "[15,6,8,19,'Class1'], \n",
    "[8,3,21,5,'Class2'], \n",
    "[10,9,14,7,'Class2'], \n",
    "[7,5,16,float('nan'),'Class2'] ] \n",
    "\n",
    "df = pd.DataFrame(data, columns = ['A', 'B' , 'C' , 'D' , 'E'] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic information about the data frame\n",
    "\n",
    "Once a data frame has been created, the data set can be examined using a number of methods that are available within the Pandas library. These methods will be explained using the simple data set that was shown above. \n",
    "\n",
    "After you have run the cell above, you can inspect the contents by using a print command, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks as follows:\n",
    "\n",
    "```\n",
    "    A   B   C     D       E\n",
    "0  12   5   6  12.0  Class1\n",
    "1  14  11  17  20.0  Class1\n",
    "2  15   6   8  19.0  Class1\n",
    "3   8   3  21   5.0  Class2\n",
    "4  10   9  14   7.0  Class2\n",
    "5   7   5  16   NaN  Class2\n",
    "```\n",
    "\n",
    "As you can see, this is a data set consting of five columns and six rows. The first line defines the names of the columns. The actual values are on the six lines that follow. The first columns contain numbers, and the fifth column, named ‘E’, classifies the data into two separate classes. Also note that, on the final line, the value for column D is missing.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Pandas has assigned number to all the rows. These numbers are referred to as ‘indices’ (the plural form of ‘index’). \n",
    "\n",
    "Additionally, the columns have all been given a name. In this particular example, the columns names have been taken from the `columns` parameter in the `DataFrame` method used to create the dataframe. \n",
    "\n",
    "When you create a dataframe out of a CSV file, using `read_csv`, these columns names are usually copied from the header of the CSV file. The header consists of a number of strings, delimited by commas, and it should be on the very first line of the CSV file. Following the execution of the `read_csv()` method, these separate strings all become available as column names. \n",
    "\n",
    "Pandas represents the missing value in column E of the row with index 5 using the code `NaN`, which stands for ‘Not a number’. If a column contains a `NaN` value, all the other numbers in this column will be shown as float values.\n",
    "\n",
    "In the case of this simple and relatively small set, the print command shown in the cell above will produce a small number of lines of output only. More realistic data science projects typically work with CSV files containing hundreds or thousands of rows, however. When we simply print the full data frame, this does not necessarily help us to develop a better understanding of the structure and the contents of the data set. In such cases, you can use a number of methods to obtain information about the data frame. \n",
    "\n",
    "To print only the first few rows of the data frame, we can work with the `head()` method. If no integer is provided within the parentheses, Pandas will show the first five rows by default. The number of rows to be shown can be specified, however, within the parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.head(2) )\n",
    "df.head(3)\n",
    "# This will print the first two records of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` property can also come in handy. It returns information about the number of rows and columns. Note that `shape` needs to be used WITHOUT parentheses, as it is a property and not a method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.shape )\n",
    "# In the current example, the shape property has the value (6, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can request an overview of all the column names that are available in a data frame using the property named `columns`. For the sake of readability, the so-called ‘Index’ object that generated by this property is converted to a list using the tolist() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column headings:\")\n",
    "print( df.columns.tolist() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "The values in a column of a data frame can be accessed separately using the name of the column. This assumes, obviously, that such column names have been defined. In order to obtain the data in a specific column, the name of the column must be appended to the name of the full data frame using square brackets, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will print all the values in the column named 'A'. Pandas stores the values in the columns using a data structure that is known as a `Series`. Simply put, a Series is a variable that brings together multiple values. A series is similar to a regular list in Python. An important difference between regular Python lists and the Series used in Pandas is that, in the latter data structure, the individual items consist of two values: (1) the actual items and (2) the indices of these items. When you print the Series using the code that was shown, you also see these two rows of values. \n",
    "\n",
    "It can be useful, in some situations, to convert a given Series into a regular list. There is a simple method named `tolist()` which you can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df['A'].tolist() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, there are often multiple ways of doing the same thing. Instead of working with the `tolist()` method, you can also invoke the standard `list()` function, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( list(df['A']) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical functions\n",
    "\n",
    "Within Pandas, you can use methods such as `max()`, `min()`, `mean()` to receive basic statistical information about numerical values in your data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df['A'].max() )\n",
    "## max() identifies the highest number within the column that is mentioned within the square brackets.\n",
    "\n",
    "print( df['B'].min() )\n",
    "# min() identifies the lowest number\n",
    "\n",
    "print( df['C'].mean() )\n",
    "# mean() calculates the mean of all the values in a specific column\n",
    "\n",
    "print( df['D'].sum() )\n",
    "## sum() performs an addition of all the numbers in a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to perform statistical analyses on all the columns of the dataframe, you can also append the name of the method you need directly to the data frame variable, without specifying a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( df.sum() )\n",
    "## This will print the sum of the values of all the columns n the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this particular method for calculating summations will only produce meaningful results in the case of numerical values. If the column contains strings, as in the case of column ‘E’ of our sample data set, this method will simply concatenate all the string values in the Series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigating a data frame\n",
    "\n",
    "To iterate across all the rows in a data frame, you can make use of the iterrows() method. This method processes the data frame row by row. When you use `iterrows()`, pandas will create a new Series for each individual row. This Series will contain all the individual values on that row. Secondly, the method also returns each row’s index. \n",
    "\n",
    "In the code below, the method `iterrows()` navigates across all the rows in the data frame. During each iteration, the compound variable named row will be assigned all the values that are available on a given row. When the variable row is used in combination with a column name, this variable will represent the data value in that particular column. The method `iterrows()` can also return the index of each row, but that index is not actually used in the fragment that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index , row in df.iterrows():\n",
    "    print( row['B'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting subsets\n",
    "\n",
    "In the pandas library, it is also possible to filter data sets. In other words, we can create new data sets containing only some of the rows or the columns of the original data sets. Such filtered data sets are also referred to as subsets. This process of ‘subsetting’ a data frame takes place on the basis of specific criteria. Different types of criteria are possible. \n",
    "\n",
    "### Filtering by index\n",
    "\n",
    "As a first possibility, we can use the indices of rows and of columns as criteria. These indices need to be added to the data frame using the `iloc[]` indexer. \n",
    "\n",
    "When we want to select all the values on the third row of the data frame (i.e. the row with index 2), this can be accomplished using the code below. The third row has index number '2', because pandas start counting at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select a number of rows simultaneously. To do this, we need to specify where the range should start and where it should end. These two numbers need to be separated by a colon. Note that the row with the index that is mentioned secondly will NOT be in the subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0:2]\n",
    "# This selects the first two rows; those with indices 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the first value is 0, as in the examole above, it can also be omitted. The code that was given can be reformulated as `df.iloc[:2]`\n",
    "\n",
    "It is also possible to filter the columns, on the basis of their indices. The indices ranges for the rows and the columns need to be separated by a comma. \n",
    "\n",
    "The next example firstly selects the second and the third row. After the comma in `iloc`, there is another set of indices. These are the indices of the columns. This code additionally selects the first and the second column of the rows that are selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 0:2 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by values\n",
    "\n",
    "A potential disadvantage of this `iloc[]` selector is that you need to know the exact values for the indices. In most situations, it is more useful to create subsets on the basis of criteria applied to the values in the data set. Imagine, for instance, that you are only interested in rows in which the column B contains a value of 5 or higher. To select those rows, you can work with the Boolean expression `df['B'] >= 5`. This Boolean expression can be added to the original data frame in square brackets. In the code that follows, the subset is assigned to a new data frame, one named `new_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[ df['B'] >= 5 ]\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar syntax can be used to filter on the basis of string values. The code below selects all the rows that belong to `Class1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[ df['E'] == 'Class1' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the columns may also be combined. The following example selects rows only if the sum of the values in columns ‘A’ and ‘B’ is higher than 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[ ( df['A'] + df['B'] ) > 20 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some types of calculations, it can be problematic if there are rows with missing values. To avoid such issues, you may want to remove all the records containing such missing values. This can be done easily using the `dropna()` method. The code below removes the row with index 5 from the df dataframe, as the column ‘E’ was left empty on this specific row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsets of columns\n",
    "\n",
    "Next to subsets of rows, it is also possible to create subsets of columns. More specifically, this means that we create new data frame, by copying only some of the columns that are available in another data frame. The easiest way to accomplish this is by supplying a list of the column names that you want to keep within the square brackets appended to data frame that needs to be filtered. After running the code below, the data frame named `new_df` has the exact same number of rows as df, but it only contains three of its columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['A', 'B', 'D']\n",
    "new_df = df[ columns ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to delete a single column from a data frame, you can make use of the `drop()` method. The columns parameter of this method needs to mention the name of the column that needs to be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(columns=\"E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations\n",
    "\n",
    "One of the great strengths of Pandas is that it can make calculations using the values captured in data frames. Such calculations can be carried out using the regular mathematical operators in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the values of columns A and B \n",
    "print( df['A'] + df['B'] )\n",
    "\n",
    "# Multiply all values in column C by 2\n",
    "print( 2 * df['C'] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of these calculations can also be stored within the data frame itself. In the code below, a new column named ‘F’ will be added to df, and it will receive the result of the calculation to the right of the equals sign. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the same number 3 to all the values in column D\n",
    "df['F'] = df['D'] + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping items and aggregation\n",
    "\n",
    "Pandas also offers a method named `groupby()` which can be very useful when your data set contains labels or categories for specific records. Using `groupby()`, the records which have been assigned the same category can all be placed in a single group. Subsequently, it becomes possible to perform calcutions for each group that has been created. This process is demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('E').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was indicated above, Column E of the data frame `df` contains labels which place the rows either in ‘Class1’ or in ‘Class2’. The name of this column can be used as a parameter for `groupby()`. The method then creates the various groups, based on the values it finds in the column that is mentioned. Once the groups have been established, you can apply statistical functions to each of theses. Examples of such statistical functions include `mean()`, `sum()` or `max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('E').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, you can see that Pandas performs calculations for all the columns in the data frame. If you would like to see the values for only one column, you can simply append the name of this column in square brackets, directly following the `groupby()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('E')['A'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.1.\n",
    "\n",
    "Download the CSV file ‘nobel.csv’: \n",
    "https://edu.nl/3xmbd  \n",
    "\n",
    "Using the data in this file, try to answer the following questions:\n",
    "* How many Nobel laureates are described in this file?\n",
    "* How many of these are from the Netherlands? What are the names of the Dutch Nobel prize winners?\n",
    "* How many female Nobel laureates are there in this data set? What are their names?\n",
    "* Who was the youngest person ever to receive the Nobel Prize? Who was the oldest person? \n",
    "Tip: create a new column called ‘Age’, in which the year in which the prize was awarded is subtracted from the year of birth. The year of birth can be extracted from the date of birth using the following code: \n",
    "> `nobel['Birth Year'] = pd.to_datetime(nobel['Birth Date']).dt.year`\n",
    "\n",
    "\n",
    "* For each discipline, calculate the average age of the Nobel laureates. \n",
    "* Create a list of all the unique countries, and calculate the number of Nobel laureates per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nobel = pd.read_csv( 'nobel.csv' )\n",
    "\n",
    "\n",
    "# Each row describes a nobel laureate\n",
    "# The number of rows and columns can be found using 'shape'\n",
    "# 'shape' results in a so-called tuple, with two values. To print only the first value,\n",
    "# use shape[0]\n",
    "\n",
    "## Number of Dutch Nobel laureates\n",
    "\n",
    "## Names of Dutch Nobel laureates\n",
    "    \n",
    "    \n",
    "## Number of female Nobel laureates\n",
    "\n",
    "## Names of female Nobel laureates\n",
    "        \n",
    "\n",
    "# create a new column called ‘Age’: \n",
    "# (the year in which the prize was awarded) minus (year of birth)\n",
    "\n",
    "    \n",
    "# find minimum and maximum in column 'Age'\n",
    "\n",
    "# print the names of these Nobel laureates, using iterrows()\n",
    "\n",
    "\n",
    "\n",
    "# For each discipline, calculate the average age of the Nobel laureates.\n",
    "# First, divide the data frame into groups based on 'Category', using groupby('Category')\n",
    "# In these groups, select only the 'Age' column, by appending ['Age']\n",
    "# Next calculate the mean. \n",
    "\n",
    "\n",
    "    \n",
    "# For each country, the number of nobel laureates\n",
    "# First, divide the data frame into groups based on 'Birth Country'\n",
    "\n",
    "# In these groups, select only the 'Laureate ID' column, by appending ['Laureate ID']\n",
    "# Next, calculate the number of rows in each group, using count() \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.2.\n",
    "\n",
    "Download the Excel file names 'Grades.xsl' from the following address: \n",
    "\n",
    "https://edu.nl/m6w8n\n",
    "\n",
    "This spreadsheet contains the partial grades received in a certain course. \n",
    "\n",
    "Write code which can calculate and print the final grade for each student. The essay and the exam both count for 40% the grade. The remaining 20% is determined by the presentation. All grades should have one digit after the decimal point. \n",
    "\n",
    "Print a list with the full names of the students, together with their final grade for the course.\n",
    "\n",
    "Additionally, answer the following questions:\n",
    "* Which student has received the highest mark for the essay?\n",
    "* Which student scored worst on the presentation? \n",
    "* How many students have received a 6 or lower for the exam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.3\n",
    "\n",
    "In the exercise, we make use of the following data set: \n",
    "\n",
    "> Fatah-Black, Dr KJ (Leiden University) (2017): Lijsten van de leveranties, met de namen van de kopers en betaalde prijzen op de verkopingen van de VOC kamer Zeeland, 1725 – 1777. DANS. https://doi.org/10.17026/dans-23z-ez6f\n",
    "\n",
    "This data set lists the goods that have been sold at VOC auctions in Zeeland in the 18th century. For each transaction, data is available about the name of the buyer, the product that was bought, the date of the transaction and the price that was paid. The price is specified in Flemish pounds and groten. 1 Flemish pound was equal to 20 groten. \n",
    "\n",
    "For the purpose of this exercise, the original data set has been changed slightly. Some rows containing invalid data were removed. Column names and values were also translated into English. The modified CSV file can be downloaded from https://tdm.universiteitleiden.nl/Python/voc-data.csv\n",
    "\n",
    "As this data set offers information about the sale of coffee only, we can use these data to trace the historical development of the price of one pound of coffee during the period that is covered by the data set. **Try to create a CSV file containing the following two columns: the full date and the average price of a pound of coffee on that date**. \n",
    "\n",
    "Follow the steps below.\n",
    "\n",
    "Firstly, add code below to download the data set. The code to write the file to disk is already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# FIXME: add code to download the CSV file from the URL 'https://tdm.universiteitleiden.nl/Python/voc-data.csv'\n",
    "# Make sure to assign the file contents to the data_file variable\n",
    "\n",
    "\n",
    "# Write to voc-data.csv in the current working directory\n",
    "with open('voc-data.csv', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded the CSV file, you can access the data values in this file using the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's load the data into a data frame named `voc`:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the contents data set, write some code to see the number of rows and columns, the columns names and all the values in te first 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difficulty in the original data set is that the year, the month and the day are captured in different columns. \n",
    "\n",
    "In a time series visualisation, dates can best be represented using a variable of the type `datetime`. Pandas has a convenient method named [`pd.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) which can assemble a datetime out of multiple columns. \n",
    "\n",
    "Write some code to add a new column to the existing data frame which can can create a new `datetime` object by combining the values found in the columns named `year`, `month` and `day`. Save this new datetime object in a column named 'date'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to calculate the total price that was paid for the product in each individual transaction. Store the result of this calculation in a column named ‘total price’. The total price can be calculated by adding the values in the column ‘flemish_pounds' and the values in the column ‘groten’, divided by 20. \n",
    "\n",
    "To be able to compare the prices, they obviously need to be normalised. This can be done by dividing the total price by the amount of coffee that purchased. All quantities are given in pounds, so if we calculate the values in the ‘total price’ column by the quantities, this should result in the price per point. Save the results of this calculation in a column named ‘price_per_pound’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains a number of records with missing data. In such cases, the values in the empty columns are represented using the code `NaN`, which stands for ‘Not a Number’. To remove all the records in which at least on of the column contains a missing value, we can make use of the dropna() method. If we only want to remove records if the have a `NaN` value in a specific column, we can work with the `subset` parameter, which needs to refer to the name of this column, as follows:\n",
    "\n",
    "`df.dropna(subset = ['column_name'])`\n",
    "\n",
    "Add some code which can remove records in which the 'price_per_pound' column has a `NaN` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one final operation we need to complete to arrive at the correct values. The original data set contains data about the prices paid in individual transactions. We want to know the average prices per day. Calculate the average prices per day, by making use use of the `groupby()` and the `mean()` function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the data frame as a CSV file using Panda's `to_csv` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas' built-in functionality\n",
    "voc.to_csv('prices_of_coffee_over_time.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.4\n",
    "\n",
    "Download the CSV file 'gutenberg_metadata.csv' via the url [https://edu.nl/xcm3q](https://edu.nl/xcm3q). \n",
    "\n",
    "Using this CSV file, create a dataframe which only contains the English texts written by Charles Dickens. In the data set, this name is given as 'Dickens, Charles'. Use the code 'en' for 'English'. \n",
    "\n",
    "Two different conditions can be combined using the amoersand ('&'). The combined criteria must be given in brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get('https://edu.nl/xcm3q')\n",
    "if response.status_code == 200:\n",
    "    csv = response.text\n",
    "    with open('gutenberg_metadata.csv' , 'w' , encoding = 'utf-8') as f:\n",
    "        f.write(csv)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
