{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.1.\n",
    "\n",
    "Download “P.B. Shelley's Complete Poems” from the following URL:  \n",
    "[https://edu.nl/r6dn8](https://edu.nl/r6dn8)\n",
    "\n",
    "Regular expressions can be used to find verse lines with specific properties. Write a program in Python which can identify verse lines with the following features: \n",
    "\n",
    "* Lines containing the word \"fire\". \n",
    "* Lines that containing either the word \"sun\" or to word \"moon\". \n",
    "* Use a single regular expression to identify these lines. \n",
    "* All the lines which contain either the singular or the plural form of \"star\". \n",
    "* All the lines which contain either the singular or the plural form of \"leaf\". \n",
    "* Lines with words ending in in \"ly\". \n",
    "* All the lines which contain a question mark. \n",
    "* Lines ending in the character combination \"ain\". \n",
    "* Cases of alliteration on \"br\" (or, in other words, all the lines which contain at least two words that begin with \"br\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "poems = open(\"Shelley.txt\" , encoding='utf-8')\n",
    "lines = []\n",
    "\n",
    "\n",
    "for line in poems:\n",
    "    lines.append(line)\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r\"\\bfire\\b\" , line , re.IGNORECASE ):\n",
    "        print(line)\n",
    "\n",
    "\n",
    "# Using the same text, print all the lines containing either the word \"sun\" or to word \"moon\". Use a single regular expression to identify these lines.\n",
    "\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'\\bsun\\b|\\bmoon\\b' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines which contain either the singular or the plural form of \"star\".\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'\\bstars?\\b' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines which contain either the singular or the plural form of \"leaf\".\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'\\blea(f|ves)\\b' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines which contain a word ending in in \"ly\".\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'ly\\b' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines which contain a question mark.\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'\\?' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines ending in the character sequence \"ain\".\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'ain$' , line ):\n",
    "        print( line )\n",
    "\n",
    "\n",
    "# Find all the lines which contain at least two words that begin with \"br\"\n",
    "\n",
    "\n",
    "\n",
    "for line in lines:\n",
    "    if re.search( r'\\bbr.+\\bbr.*' , line ):\n",
    "        print( line )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.2.\n",
    "\n",
    "Download the file “bibliography.txt” from \n",
    "[https://edu.nl/t449h](https://edu.nl/t449h)\n",
    "\n",
    "This file contains a list of articles, formatted according to the APA citation style. For each title, try to extract the year of publication, the title and the name of the journal.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2010)\n",
      "How a Prototype Argues.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2011)\n",
      "Who You Calling Untheoretical?\n",
      "Journal of Digital Humanities \n",
      "\n",
      "(2013)\n",
      "The Perils of the ‘Digital Humanities’: New Positivisms and the Fate of Literary Theory.\n",
      "Postmodern Culture \n",
      "\n",
      "(2008)\n",
      "The End of Theory: The Data Deluge Makes the Scientific Method Obsolete.\n",
      "Wired Magazine \n",
      "\n",
      "(2008)\n",
      "Information Visualization for Humanities Scholars.\n",
      "Wired Magazine \n",
      "\n",
      "(2008)\n",
      "What Is Knowledge Visualization? Perspectives on an Emerging Discipline.\n",
      "Wired Magazine \n",
      "\n",
      "(2013)\n",
      "What Makes a Visualization Memorable.\n",
      "IEEE Transactions on Visualization and Computer Graphics \n",
      "\n",
      "(2011)\n",
      "Humanities Approaches to Graphical Display.\n",
      "Digital Humanities Quarterly \n",
      "\n",
      "(2005)\n",
      "In Praise of Pattern.\n",
      "TEXT Technology \n",
      "\n",
      "(2017)\n",
      "A Data-Oriented Model of Literary Language.\n",
      "TEXT Technology \n",
      "\n",
      "(2013)\n",
      "The Stylistics and Stylometry of Collaborative Translation: Woolf’s Night and Day in Polish.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2012)\n",
      "Testing Authorship in the Personal Writings of Joseph Smith Using NSC Classification.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2012)\n",
      "Co-Occurrence-Based Indicators for Authorship Analysis.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2012)\n",
      "Detecting Authorship Deception: A Supervised Machine Learning Approach Using Author Writeprints.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2011)\n",
      "Looking for Translator’s Fingerprints: A Corpus-Based Study on Chinese Translations of Ulysses.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2011)\n",
      "Deeper Delta across Genres and Languages: Do We Really Need the Most Frequent Words?\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2011)\n",
      "Evidence of Intertextuality: Investigating Paul the Deacon’s Angustae Vitae.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2011)\n",
      "Translation Style and Ideology: A Corpus-Assisted Analysis of Two English Translations of Hongloumeng.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2010)\n",
      "Automatically Extracting Typical Syntactic Differences from Corpora.\n",
      "Literary and Linguistic Computing \n",
      "\n",
      "(2010)\n",
      "The Regressive Imagery Dictionary: A Test of Its Concurrent Validity in English, German, Latin, and Portuguese.\n",
      "Literary and Linguistic Computing \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "file = open(  \"bibliography.txt\" )\n",
    "\n",
    "for pub in file:\n",
    "    matches = re.findall( r'\\(\\d+\\)' , pub )\n",
    "    if matches:\n",
    "        year = matches[0]\n",
    "\n",
    "    matches = re.findall( r'\\\".+\\\"' , pub )\n",
    "    if matches:\n",
    "        title = matches[0]\n",
    "        title = re.sub( '^\\\"|\\\"$' , '' , title )\n",
    "        \n",
    "        \n",
    "    \n",
    "    matches = re.findall( r'\\\".+\\\"\\s([A-Za-z\\s]*)\\d' , pub )\n",
    "    if matches:\n",
    "        journal = matches[0]\n",
    "        \n",
    "    print( f'{year}\\n{title}\\n{journal}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9.3.\n",
    "\n",
    "Download the file “tweets.txt” from [https://edu.nl/cvge6](https://edu.nl/cvge6).\n",
    "\n",
    "This file contains a number of tweets containing the hashtag ‘#universiteitleiden’, obtained using the Twitter API. Extract all the usernames and all the hashtags form these tweets, using regular expressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tweets = open( 'tweets.txt' , encoding = 'utf-8')\n",
    "\n",
    "hashTags = dict()\n",
    "userNames = dict()\n",
    "\n",
    "for t in tweets:\n",
    "    \n",
    "    ht = re.findall( r'#\\w+\\b' , t )\n",
    "    for h in ht:\n",
    "        hashTags[h] = hashTags.get( h , 0 ) + 1\n",
    "    un = re.findall( r'@\\w+\\b' , t )\n",
    "    for u in un:\n",
    "        userNames[u] = userNames.get( u , 0 ) + 1\n",
    "        \n",
    "print(\"Hashtags:\")        \n",
    "for ht in hashTags:\n",
    "    print(ht)\n",
    "    \n",
    "print(\"\\nUser names:\")     \n",
    "    \n",
    "for u in userNames:\n",
    "    print(u)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
