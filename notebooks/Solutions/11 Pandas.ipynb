{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.1.\n",
    "\n",
    "Download the CSV file ‘nobel.csv’: \n",
    "https://edu.nl/3xmbd  \n",
    "\n",
    "Using the data in this file, try to answer the following questions:\n",
    "\n",
    "11.1.a. How many Nobel laureates are described in this file?\n",
    "\n",
    "11.1.b. How many of these are from the Netherlands? What are the names of the Dutch Nobel prize winners?\n",
    "\n",
    "11.1.c. How many female Nobel laureates are there in this data set? What are their names?\n",
    "\n",
    "11.1.d. Who was the youngest person ever to receive the Nobel Prize? Who was the oldest person? \n",
    "\n",
    "Tip: create a new column called ‘Age’, in which the year in which the prize was awarded is subtracted from the year of birth. The year of birth can be extracted from the date of birth using the following code: \n",
    "> `nobel['Birth Year'] = pd.to_datetime(nobel['Birth Date']).dt.year`\n",
    "\n",
    "\n",
    "11.1.e. For each discipline, calculate the average age of the Nobel laureates. \n",
    "\n",
    "11.1.f. Create a list of all the unique countries, and calculate the number of Nobel laureates per country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nobel laureates: 969\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "path_to_csv = join('..','Data','nobel.csv')\n",
    "nobel = pd.read_csv( path_to_csv )\n",
    "\n",
    "# Each row describes a nobel laureate\n",
    "# The number of rows and columns can be found using 'shape'\n",
    "# 'shape' results in a so-called tuple, with two values. To print only the first value,\n",
    "# use shape[0]\n",
    "print( 'Number of nobel laureates: {}'.format(nobel.shape[0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of Dutch Nobel laureates: 19\n",
      "Jacobus Henricus van 't Hoff\n",
      "Hendrik Antoon Lorentz\n",
      "Pieter Zeeman\n",
      "Johannes Diderik van der Waals\n",
      "Tobias Michael Carel Asser\n",
      "Heike Kamerlingh Onnes\n",
      "Christiaan Eijkman\n",
      "Petrus (Peter) Josephus Wilhelmus Debye\n",
      "Petrus (Peter) Josephus Wilhelmus Debye\n",
      "Frits Zernike\n",
      "Jan Tinbergen\n",
      "Nikolaas Tinbergen\n",
      "Tjalling C. Koopmans\n",
      "Nicolaas Bloembergen\n",
      "Simon van der Meer\n",
      "Paul J. Crutzen\n",
      "Gerardus 't Hooft\n",
      "Martinus J.G. Veltman\n",
      "Bernard L. Feringa\n"
     ]
    }
   ],
   "source": [
    "## Number of Dutch nobel laureates\n",
    "dutch = nobel[ nobel['Birth Country'] == 'Netherlands' ]\n",
    "print( '\\n\\nNumber of Dutch Nobel laureates: {}'.format(dutch.shape[0] ) )\n",
    "\n",
    "for index, row in dutch.iterrows():\n",
    "    print( row['Full Name'] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of female Nobel laureates: 50\n",
      "Marie Curie, née Sklodowska\n",
      "Baroness Bertha Sophie Felicita von Suttner, née Countess Kinsky von Chinic und Tettau\n",
      "Selma Ottilia Lovisa Lagerlöf\n",
      "Marie Curie, née Sklodowska\n",
      "Grazia Deledda\n",
      "Sigrid Undset\n",
      "Jane Addams\n",
      "Irène Joliot-Curie\n",
      "Pearl Buck\n",
      "Gabriela Mistral\n",
      "Emily Greene Balch\n",
      "Gerty Theresa Cori, née Radnitz\n",
      "Maria Goeppert Mayer\n",
      "Dorothy Crowfoot Hodgkin\n",
      "Nelly Sachs\n",
      "Betty Williams\n",
      "Mairead Corrigan\n",
      "Rosalyn Yalow\n",
      "Mother Teresa\n",
      "Alva Myrdal\n",
      "Barbara McClintock\n",
      "Rita Levi-Montalcini\n",
      "Gertrude B. Elion\n",
      "Nadine Gordimer\n",
      "Aung San Suu Kyi\n",
      "Rigoberta Menchú Tum\n",
      "Toni Morrison\n",
      "Christiane Nüsslein-Volhard\n",
      "Wislawa Szymborska\n",
      "Jody Williams\n",
      "Shirin Ebadi\n",
      "Elfriede Jelinek\n",
      "Linda B. Buck\n",
      "Wangari Muta Maathai\n",
      "Doris Lessing\n",
      "Françoise Barré-Sinoussi\n",
      "Ada E. Yonath\n",
      "Elinor Ostrom\n",
      "Elinor Ostrom\n",
      "Herta Müller\n",
      "Elizabeth H. Blackburn\n",
      "Carol W. Greider\n",
      "Ellen Johnson Sirleaf\n",
      "Leymah Gbowee\n",
      "Tawakkol Karman\n",
      "Alice Munro\n",
      "May-Britt Moser\n",
      "Malala Yousafzai\n",
      "Svetlana Alexievich\n",
      "Youyou Tu\n"
     ]
    }
   ],
   "source": [
    "## Number of Female nobel laureates\n",
    "female = nobel[ nobel['Sex'] == 'Female' ]\n",
    "print( '\\n\\nNumber of female Nobel laureates: {}'.format(female.shape[0] ) )\n",
    "\n",
    "for index, row in female.iterrows():\n",
    "    print( row['Full Name'] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The oldest Nobel laureate was Leonid Hurwicz, aged 90.0.\n",
      "The youngest Nobel laureate was Malala Yousafzai, aged 17.\n"
     ]
    }
   ],
   "source": [
    "# extract the year of birth from the birth date\n",
    "nobel['Birth Year'] = pd.to_datetime(nobel['Birth Date']).dt.year\n",
    "\n",
    "# calculate age by subtracting birth year from year of nobel prize \n",
    "nobel['Age'] = nobel['Year'] - nobel['Birth Year']\n",
    "\n",
    "# find minimum and maximum in column 'Age'\n",
    "youngest = nobel['Age'].min()\n",
    "oldest = nobel['Age'].max()\n",
    "\n",
    "print('\\n')\n",
    "# print the names of these Nobel laureates, using iterrows()\n",
    "for index, row in nobel.iterrows():\n",
    "    if row['Age'] == youngest:\n",
    "        print('The youngest Nobel laureate was {}, aged {}.'.format( row['Full Name'] , int(row['Age'])))\n",
    "    if row['Age'] == oldest:\n",
    "        print( 'The oldest Nobel laureate was {}, aged {}.'.format( row['Full Name'] , row['Age']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The average age in each category:\n",
      "Category\n",
      "Chemistry     58.134715\n",
      "Economics     67.048193\n",
      "Literature    64.672566\n",
      "Medicine      57.933921\n",
      "Peace         61.394231\n",
      "Physics       55.850000\n"
     ]
    }
   ],
   "source": [
    "# For each discipline, calculate the average age of the Nobel laureates.\n",
    "# First, divide the data frame into groups based on 'Category', using groupby('Category')\n",
    "# In these groups, select only the 'Age' column, by appending ['Age']\n",
    "# Next calculate the mean. The result is a Series object. \n",
    "# You can get the indices of this Series using the 'index' property\n",
    "print('\\nThe average age in each category:')\n",
    "average_age = nobel.groupby('Category')['Age'].mean() \n",
    "\n",
    "print( average_age.to_string() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of Nobel laureates per country\n",
      "Argentina: 4\n",
      "Australia: 11\n",
      "Austria: 15\n",
      "Austria-Hungary (Austria): 2\n",
      "Austria-Hungary (Bosnia and Herzegovina): 1\n",
      "Austria-Hungary (Croatia): 1\n",
      "Austria-Hungary (Czech Republic): 4\n",
      "Austria-Hungary (Hungary): 3\n",
      "Austria-Hungary (Poland): 1\n",
      "Austria-Hungary (Slovenia): 1\n",
      "Austria-Hungary (Ukraine): 1\n",
      "Austrian Empire (Austria): 2\n",
      "Austrian Empire (Czech Republic): 1\n",
      "Austrian Empire (Italy): 1\n",
      "Bavaria (Germany): 1\n",
      "Belgium: 9\n",
      "Bosnia (Bosnia and Herzegovina): 1\n",
      "Brazil: 1\n",
      "British India (Bangladesh): 1\n",
      "British India (India): 1\n",
      "British Mandate of Palestine (Israel): 5\n",
      "British Protectorate of Palestine (Israel): 1\n",
      "British West Indies (Saint Lucia): 1\n",
      "Bulgaria: 1\n",
      "Burma (Myanmar): 1\n",
      "Canada: 18\n",
      "Chile: 2\n",
      "China: 12\n",
      "Colombia: 2\n",
      "Costa Rica: 1\n",
      "Crete (Greece): 1\n",
      "Cyprus: 1\n",
      "Czechoslovakia (Czech Republic): 1\n",
      "Denmark: 11\n",
      "East Friesland (Germany): 1\n",
      "East Timor: 2\n",
      "Egypt: 6\n",
      "Faroe Islands (Denmark): 1\n",
      "Finland: 2\n",
      "France: 53\n",
      "Free City of Danzig (Poland): 1\n",
      "French Algeria (Algeria): 3\n",
      "German-occupied Poland (Poland): 1\n",
      "Germany: 70\n",
      "Germany (France): 3\n",
      "Germany (Poland): 10\n",
      "Germany (Russia): 3\n",
      "Gold Coast (Ghana): 1\n",
      "Guadeloupe Island: 1\n",
      "Guatemala: 2\n",
      "Hesse-Kassel (Germany): 1\n",
      "Hungary: 6\n",
      "Hungary (Slovakia): 1\n",
      "Iceland: 1\n",
      "India: 7\n",
      "India (Pakistan): 3\n",
      "Iran: 1\n",
      "Ireland: 5\n",
      "Italy: 18\n",
      "Japan: 29\n",
      "Java, Dutch East Indies (Indonesia): 1\n",
      "Kenya: 1\n",
      "Korea (South Korea): 2\n",
      "Liberia: 2\n",
      "Lithuania: 1\n",
      "Luxembourg: 2\n",
      "Madagascar: 1\n",
      "Mecklenburg (Germany): 1\n",
      "Mexico: 3\n",
      "Morocco: 2\n",
      "Netherlands: 19\n",
      "New Zealand: 3\n",
      "Nigeria: 1\n",
      "Northern Ireland: 5\n",
      "Norway: 13\n",
      "Ottoman Empire (Republic of Macedonia): 1\n",
      "Ottoman Empire (Turkey): 1\n",
      "Pakistan: 1\n",
      "Persia (Iran): 1\n",
      "Peru: 1\n",
      "Poland: 6\n",
      "Poland (Belarus): 1\n",
      "Poland (Lithuania): 1\n",
      "Poland (Ukraine): 1\n",
      "Portugal: 3\n",
      "Prussia (Germany): 7\n",
      "Prussia (Poland): 6\n",
      "Prussia (Russia): 1\n",
      "Romania: 5\n",
      "Russia: 20\n",
      "Russian Empire (Azerbaijan): 1\n",
      "Russian Empire (Belarus): 2\n",
      "Russian Empire (Finland): 3\n",
      "Russian Empire (Latvia): 1\n",
      "Russian Empire (Lithuania): 1\n",
      "Russian Empire (Poland): 5\n",
      "Russian Empire (Russia): 2\n",
      "Russian Empire (Ukraine): 2\n",
      "Saint Lucia: 1\n",
      "Schleswig (Germany): 2\n",
      "Scotland: 9\n",
      "South Africa: 9\n",
      "Southern Rhodesia (Zimbabwe): 1\n",
      "Spain: 7\n",
      "Sweden: 30\n",
      "Switzerland: 17\n",
      "Taiwan: 1\n",
      "Tibet (People's Republic of China): 1\n",
      "Trinidad: 1\n",
      "Turkey: 2\n",
      "Tuscany (Italy): 1\n",
      "Ukraine: 1\n",
      "Union of Soviet Socialist Republics (Belarus): 1\n",
      "Union of Soviet Socialist Republics (Russia): 4\n",
      "United Kingdom: 88\n",
      "United States of America: 276\n",
      "Venezuela: 1\n",
      "Vietnam: 1\n",
      "W&uuml;rttemberg (Germany): 1\n",
      "West Germany (Germany): 5\n",
      "Yemen: 1\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all the unique countries, and calculate \n",
    "# the number of Nobel laureates per country.\n",
    "# First, divide the data frame into groups based on 'Birth Country', using groupby('Category')\n",
    "# In these groups, select only the 'Laureate ID' column, by appending ['Laureate ID']\n",
    "# Next, calculate the number of rows in each group, using count() \n",
    "# The result is a Series object. \n",
    "# You can get the indices of this Series using the 'index' property  \n",
    "\n",
    "print('\\nThe number of Nobel laureates per country')\n",
    "countries = nobel.groupby('Birth Country')['Laureate ID'].count()\n",
    "for c in countries.index:\n",
    "    print( '{}: {}'.format( c , countries[c] ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.2.\n",
    "\n",
    "Download the Excel file names 'Grades.xsl' from the following address: \n",
    "\n",
    "https://edu.nl/m6w8n\n",
    "\n",
    "This spreadsheet contains the partial grades received in a certain course. \n",
    "\n",
    "Write code which can calculate and print the final grade for each student. The essay and the exam both count for 40% the grade. The remaining 20% is determined by the presentation. All grades should have one digit after the decimal point. \n",
    "\n",
    "Print a list with the full names of the students, together with their final grade for the course.\n",
    "\n",
    "Additionally, answer the following questions:\n",
    "* Which student has received the highest mark for the essay?\n",
    "* Which student scored worst on the presentation? \n",
    "* How many students have received a 6 or lower for the exam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Grades.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nf/35gdwksd0fx8kzbsljz4dz6hnrcnxq/T/ipykernel_89446/2564310518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'Grades.xlsx'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Sheet1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1192\u001b[0;31m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 )\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     with get_handle(\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     ) as handle:\n\u001b[1;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Grades.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel( 'Grades.xlsx' , sheet_name = \"Sheet1\")\n",
    "\n",
    "df.columns.tolist()\n",
    "\n",
    "df['final_mark'] = round( 0.4 * df['Essay'] + 0.4 * df['Exam'] + 0.2 * df['Presentation'] , 1 ) \n",
    "\n",
    "df = df.sort_values(['Last'])\n",
    "\n",
    " \n",
    "best_essays = df[ df['Essay'] == df['Essay'].max() ] \n",
    "worst_presentations = df[ df['Presentation'] == df['Presentation'].min() ] \n",
    "insufficient_exam = df[ df['Exam'] < 6 ] \n",
    "\n",
    "print('Best essay:')\n",
    "for index , row in best_essays.iterrows():\n",
    "    print( '{} {}: {}'.format( row['First'] , row['Last'] , row['Essay'] ) )\n",
    "    \n",
    "    \n",
    "print('\\nWorst presentation:')\n",
    "for index , row in worst_presentations.iterrows():\n",
    "    print( '{} {}: {}'.format( row['First'] , row['Last'] , row['Presentation'] ) )\n",
    "\n",
    "print('\\nThe following students received an insufficient mark for the exam:')\n",
    "for index , row in insufficient_exam.iterrows():\n",
    "    print( '{} {}: {}'.format( row['First'] , row['Last'] , row['Exam'] ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the exercise, we make use of the following data set: \n",
    "\n",
    "> Fatah-Black, Dr KJ (Leiden University) (2017): Lijsten van de leveranties, met de namen van de kopers en betaalde prijzen op de verkopingen van de VOC kamer Zeeland, 1725 – 1777. DANS. https://doi.org/10.17026/dans-23z-ez6f\n",
    "\n",
    "This data set lists the goods that have been sold at VOC auctions in Zeeland in the 18th century. For each transaction, data is available about the name of the buyer, the product that was bought, the date of the transaction and the price that was paid. The price is specified in Flemish pounds and groten. 1 Flemish pound was equal to 20 groten. \n",
    "\n",
    "For the purpose of this exercise, the original data set has been changed slightly. Some rows containing invalid data were removed. Column names and values were also translated into English. The modified CSV file can be downloaded from https://tdm.universiteitleiden.nl/Python/voc-data.csv\n",
    "\n",
    "As this data set offers information about the sale of coffee only, we can use these data to trace the historical development of the price of one pound of coffee during the period that is covered by the data set. **Try to create a CSV file containing the following two columns: the full date and the average price of a pound of coffee on that date**. \n",
    "\n",
    "Follow the steps below.\n",
    "\n",
    "Firstly, add code below to download the data set. The code to write the file to disk is already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# FIXME: add code to download the CSV file from the URL 'https://tdm.universiteitleiden.nl/Python/voc-data.csv'\n",
    "# Make sure to assign the file contents to the data_file variable\n",
    "response = requests.get('https://tdm.universiteitleiden.nl/Python/voc-data.csv')\n",
    "if response.status_code == 200:\n",
    "    data_file = response.text\n",
    "\n",
    "# Write to voc-data.csv in the current working directory\n",
    "with open('voc-data.csv', 'w', encoding='utf-8') as output_file:\n",
    "    output_file.write(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have downloaded the CVS file, you can access the data values in this file using the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's load the data into a data frame named `voc`:\n",
    "voc = pd.read_csv('voc-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the contents data set, write some code to see the number of rows and columns, the columns names and all the values in te first 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( voc.shape )\n",
    "print( voc.columns.tolist() )\n",
    "voc.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difficulty in the original data set is that the year, the month and the day are captured in different columns. \n",
    "\n",
    "In a time series visualisation, dates can best be represented using a variable of the type `datetime`. Pandas has a convenient method named [`pd.to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) which can assemble a datetime out of multiple columns. \n",
    "\n",
    "Write some code to add a new column to the existing data frame which can can create a new `datetime` object by combining the values found in the columns named `year`, `month` and `day`. Save this new datetime object in a column named 'date'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc['date'] = pd.to_datetime(voc[['year', 'month', 'day']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to calculate the total price that was paid for the product in each individual transaction. Store the result of this calculation in a column named ‘total price’. The total price can be calculated by adding the values in the column ‘flemish_pounds' and the values in the column ‘groten’, divided by 20. \n",
    "\n",
    "To be able to compare the prices, they obviously need to be normalised. This can be done by dividing the total price by the amount of coffee that purchased. All quantities are given in pounds, so if we calculate the values in the ‘total price’ column by the quantities, this should result in the price per point. Save the results of this calculation in a column named ‘price_per_pound’. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc['total_price'] = voc['flemish_pounds'] + (voc['groten'] / 20)\n",
    "voc['price_per_pound']  = voc['total_price']  / voc['quantity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains a number of records with missing data. In such cases, the values in the empty columns are represented using the code `NaN`, which stands for ‘Not a Number’. To remove all the records in which at least on of the column contains a missing value, we can make use of the dropna() method. If we only want to remove records if the have a `NaN` value in a specific column, we can work with the `subset` parameter, which needs to refer to the name of this column, as follows:\n",
    "\n",
    "`df.dropna(subset = ['column_name'])`\n",
    "\n",
    "Add some code which can remove records in which the 'price_per_pound' column has a `NaN` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = voc.dropna(subset = ['price_per_pound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one final operation we need to complete to arrive at the correct values. The original data set contains data about the prices paid in individual transactions. We want to know the average prices per day. Calculate the average prices per day, by making use use of the `groupby()` and the `mean()` function. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = voc.groupby('date').mean() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the data frame as a CSV file using Panda's `to_csv` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas' built-in functionality\n",
    "voc.to_csv('prices_of_coffee_over_time.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.4\n",
    "\n",
    "Download the CSV file 'gutenberg_metadata.csv' via the url [https://edu.nl/xcm3q](https://edu.nl/xcm3q). \n",
    "\n",
    "Using this CSV file, create a dataframe which only contains the English texts written by Charles Dickens. In the data set, this name is given as 'Dickens Charles'. Use the code 'en' for 'English'. \n",
    "\n",
    "Two different conditions can be combined using the amoersand ('&'). The combined criteria must be given in brackets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "response = requests.get('https://edu.nl/xcm3q')\n",
    "if response.status_code == 200:\n",
    "    csv = response.text\n",
    "    with open('gutenberg_metadata.csv' , 'w' , encoding = 'utf-8') as f:\n",
    "        f.write(csv)\n",
    "\n",
    "df = pd.read_csv('gutenberg_metadata.csv' )\n",
    "df_dickens = df[ (df['author'] == 'Dickens Charles') & (df['language'] =='en' ) ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
